##### Best Practices Neural Network

## Weights Initialization :
-	Matrices : Uniform(-Sqrt(6/(L_in+L_out), +Sqrt(6/(L_in+L_out))
-	Biases : Zero or Uniform[0,1] ?
-	http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf
-	To keep the information flowing flowing forward and backward, you want the variance of the neurons and the partial derivatives to be the same throughout the network
-	You also want to be in the zone where the derivative of the activation function is max 

## Numerical Gradient Checking
 
## Minibatches

## Gradient Normalization

## Activation Function

## Dropout

## Data Augmentation

## Ensembling


